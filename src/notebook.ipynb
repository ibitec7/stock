{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = \"/home/ibrahim/stock/data/processed\"\n",
    "YEARS = [\"2020\", \"2021\", \"2022\", \"2023\", \"2024\", \"2025\"]\n",
    "\n",
    "data = {\n",
    "    \"2020\": {\n",
    "        \"high_impact\": [],\n",
    "        \"medium_impact\": [],\n",
    "        \"low_impact\": [],\n",
    "        \"news\": []\n",
    "    },\n",
    "    \"2021\": {\n",
    "        \"high_impact\": [],\n",
    "        \"medium_impact\": [],\n",
    "        \"low_impact\": [],\n",
    "        \"news\": []\n",
    "    },\n",
    "    \"2022\": {\n",
    "        \"high_impact\": [],\n",
    "        \"medium_impact\": [],\n",
    "        \"low_impact\": [],\n",
    "        \"news\": []\n",
    "    },\n",
    "    \"2023\": {\n",
    "        \"high_impact\": [],\n",
    "        \"medium_impact\": [],\n",
    "        \"low_impact\": [],\n",
    "        \"news\": []\n",
    "    },\n",
    "    \"2024\": {\n",
    "        \"high_impact\": [],\n",
    "        \"medium_impact\": [],\n",
    "        \"low_impact\": [],\n",
    "        \"news\": []\n",
    "    },\n",
    "    \"2025\": {\n",
    "        \"high_impact\": [],\n",
    "        \"medium_impact\": [],\n",
    "        \"low_impact\": [],\n",
    "        \"news\": []\n",
    "    }\n",
    "}\n",
    "\n",
    "for year in YEARS:\n",
    "    PATHS = os.listdir(os.path.join(ROOT_DIR, year))\n",
    "    \n",
    "    for path in PATHS:\n",
    "\n",
    "        with open(os.path.join(ROOT_DIR, year, path), \"r\") as file:\n",
    "\n",
    "            if \"high\" in path:\n",
    "                data[year][\"high_impact\"] = json.load(file)\n",
    "            elif \"medium\" in path:\n",
    "                data[year][\"medium_impact\"] = json.load(file)\n",
    "            elif \"low\" in path:\n",
    "                data[year][\"low_impact\"] = json.load(file)\n",
    "            else:\n",
    "                data[year][\"news\"] = json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOTS_DIR = \"/home/ibrahim/stock/plots\"\n",
    "\n",
    "corpus = {\"2020\": {}, \"2021\": {}, \"2022\": {}, \"2023\": {}, \"2024\": {}, \"2025\": {}}\n",
    "\n",
    "for news in data:\n",
    "    for impact in data[news]:\n",
    "        if data[news][impact] is None:\n",
    "            print(f\"No data for {news} {impact}\")\n",
    "        if len(data[news][impact]) > 0:\n",
    "            text = \" \".join(data[news][impact])\n",
    "            text = text.replace(\"nvidia\", \" \")\n",
    "\n",
    "            tokens = word_tokenize(text)\n",
    "\n",
    "            corpus[news][impact] = text\n",
    "            \n",
    "            wordcloud = WordCloud(width=800, height=400, background_color=\"white\", max_words=150).generate(text)\n",
    "\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "            plt.axis(\"off\")\n",
    "            plt.title(f\"{news} {impact} Word Cloud\")\n",
    "            plt.savefig(os.path.join(PLOTS_DIR, f\"{news}_{impact}.png\"))\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import Pipeline\n",
    "\n",
    "class FinBERTPipeline(Pipeline):\n",
    "    def _sanitize_parameters(self, **kwargs):\n",
    "        preprocess_kwargs = {}\n",
    "        if \"text\" in kwargs:\n",
    "            preprocess_kwargs[\"text\"] = kwargs[\"text\"]\n",
    "        return preprocess_kwargs, {}, {}\n",
    "\n",
    "    def preprocess(self, sentence, maybe_arg=2):\n",
    "        return self.tokenizer(sentence, return_tensors=\"pt\")\n",
    "\n",
    "    def _forward(self, inputs):\n",
    "        return self.model(**inputs, output_hidden_states=True)\n",
    "\n",
    "    def postprocess(self, outputs):\n",
    "        sentence_embedding = torch.mean(outputs.hidden_states[-1][0], dim=0).numpy()\n",
    "        predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "        prediction_max_index = int(torch.argmax(predictions))\n",
    "        label = self.model.config.id2label[prediction_max_index]\n",
    "        return {'label': label, 'score': predictions[0][prediction_max_index].item(), 'embedding': sentence_embedding}\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral 0.8927797675132751 (768,)\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from transformers.pipelines import PIPELINE_REGISTRY\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "PIPELINE_REGISTRY.register_pipeline(\n",
    "   'finbert-pipeline-with-sentence-embedding',\n",
    "   pipeline_class=FinBERTPipeline,\n",
    "   pt_model=AutoModelForSequenceClassification,\n",
    ")\n",
    "\n",
    "pipe = pipeline('finbert-pipeline-with-sentence-embedding', model='ProsusAI/finbert', device=0)\n",
    "outputs = pipe('EXAMPLE SENTENCE')\n",
    "\n",
    "print(outputs['label'], outputs['score'], outputs['embedding'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.9657e-01,  1.3090e-01, -6.3200e-02, -3.8852e-02, -4.4911e-01,\n",
       "         -9.5320e-01,  7.2255e-01,  4.1358e-01, -2.3714e-01, -2.1281e-01,\n",
       "          1.9503e-01, -6.3107e-01,  3.2011e-01, -2.4609e-03, -3.1287e-01,\n",
       "         -1.9257e-01,  4.9090e-02,  3.7381e-01,  4.2787e-02, -1.5683e-01,\n",
       "          2.6213e-01,  3.8908e-02, -1.6212e-01,  1.6726e-01,  2.4482e-01,\n",
       "          5.4331e-01, -1.0891e-01,  1.7704e-01,  8.6575e-02, -3.2981e-01,\n",
       "         -1.2469e-01,  6.6089e-02, -2.2721e-01, -1.9966e-01,  4.2461e-01,\n",
       "         -5.3609e-01,  4.9235e-01, -3.5622e-01, -4.5563e-01,  1.6188e-01,\n",
       "         -1.2379e+00, -3.6276e-01, -1.3031e-01,  1.3809e-01, -2.7757e-01,\n",
       "         -2.2755e-01,  5.5868e-01,  5.0482e-01, -2.9229e-01,  8.2040e-01,\n",
       "         -3.0340e-02,  6.7432e-02, -4.1842e-01,  1.2779e-01,  3.7652e-01,\n",
       "          3.4655e-01, -3.4712e-01, -9.6518e-01, -5.5033e-01, -5.6727e-02,\n",
       "          3.1613e-01,  3.0858e-01, -6.0979e-01,  2.1034e-01,  5.7790e-01,\n",
       "          1.7279e-01,  4.2284e-03, -1.8220e-01, -1.0591e+00, -3.7974e-01,\n",
       "         -4.1905e-01, -9.6063e-01,  3.8066e-01,  3.4431e-01,  1.3796e-01,\n",
       "          9.5588e-01, -1.6865e-01,  7.4415e-01,  2.8785e-01,  4.1047e-01,\n",
       "         -6.4983e-02,  3.0918e-01, -2.0904e-01,  7.7888e-01,  2.5894e-01,\n",
       "         -4.2511e-01, -7.5740e-01, -9.9818e-02,  1.0479e-01,  1.1418e-01,\n",
       "         -1.5945e-01, -9.1334e-02,  3.8310e-01,  5.2768e-01,  2.0354e-01,\n",
       "          1.0356e+00,  1.1451e-01,  1.4449e-01, -6.8472e-01,  2.7185e-01,\n",
       "         -5.5452e-01, -6.2347e-02,  2.0232e-01,  2.9674e-01,  4.5877e-01,\n",
       "         -3.9582e-02, -8.5254e-02,  8.3619e-01,  5.4193e-01,  1.3446e+00,\n",
       "          5.3104e-01, -3.5358e-01,  3.0620e-01, -1.0996e-01, -3.5271e-01,\n",
       "         -7.2515e-01,  4.9781e-02,  1.2965e-01, -2.3531e-02, -4.4021e-01,\n",
       "         -5.6610e-01, -7.9449e-01,  4.0213e-01,  9.9667e-01, -4.9563e-01,\n",
       "          4.2516e-02, -2.6954e-01, -2.1871e-01,  3.8436e-02, -2.8806e-02,\n",
       "         -3.4456e-01,  3.7110e-01,  3.4188e-01, -5.0638e-02, -8.0611e-03,\n",
       "          2.6766e-01, -1.4620e-01,  1.0181e-01, -9.7938e-01,  4.9265e-01,\n",
       "         -5.6550e-01,  5.7122e-01,  9.3428e-01, -7.8267e-01,  7.7631e-01,\n",
       "          1.4498e-01,  1.0620e+00, -5.9455e-03,  2.5938e-01,  5.4391e-02,\n",
       "          6.8096e-01, -3.9171e-01,  2.2613e-01, -3.9545e-01, -4.5766e-01,\n",
       "         -6.5246e-01, -3.2400e-01,  4.2066e-02,  6.3708e-01,  6.3637e-01,\n",
       "          7.7788e-02, -2.9682e-01,  2.5635e-01,  3.8742e-01, -3.5052e-01,\n",
       "          7.0499e-02, -5.1276e-01,  1.7540e-02, -5.7077e-02, -2.6911e-02,\n",
       "         -4.3776e-01, -5.2172e-02,  2.4642e-01, -9.7729e-02, -1.7820e-01,\n",
       "          3.9590e-01,  2.4932e-01, -9.0073e-02,  3.9831e-01, -6.8779e-01,\n",
       "         -7.5945e+00, -4.2620e-02,  5.3015e-01,  2.6836e-01,  6.2755e-01,\n",
       "         -4.1900e-01, -6.2329e-01, -3.6591e-02,  1.3799e-02, -9.9816e-01,\n",
       "         -8.3794e-01,  3.8439e-01, -5.1690e-01,  5.0036e-01,  1.0662e+00,\n",
       "         -3.7109e-01,  2.4759e-02,  3.4611e-01, -6.7031e-01,  5.4978e-01,\n",
       "          2.8792e-01,  2.1099e-01, -9.8959e-03,  3.0312e-01, -5.6758e-01,\n",
       "         -1.9401e+00,  9.3516e-02, -4.2060e-01,  9.8594e-02,  4.0557e-01,\n",
       "         -8.6152e-01,  3.8674e-01, -2.0965e-01, -2.5812e-01,  9.6866e-02,\n",
       "          1.2209e-01, -1.2706e-01, -3.4739e-01, -8.7541e-01, -5.5745e-01,\n",
       "         -6.6050e-01, -1.4193e-01, -8.1715e-01,  4.0403e-01,  3.5296e-01,\n",
       "         -1.0911e+00, -1.0430e-01,  2.7898e-01,  3.3343e-02,  3.4355e-01,\n",
       "          4.3899e-01,  4.0992e-02,  1.0749e+00,  2.7602e-02, -1.1137e-01,\n",
       "          2.0362e-02,  2.0123e-01, -2.7225e-02, -2.5978e-01, -4.7195e-01,\n",
       "         -2.8655e-01,  1.8524e-01,  1.7351e-01, -5.1520e-01,  1.8490e-01,\n",
       "         -1.7849e-01, -4.0255e-01,  3.6667e-01,  9.0194e-01, -3.4060e-01,\n",
       "          9.5436e-02, -1.7058e-01,  4.2215e-01, -6.2839e-01,  3.6640e-01,\n",
       "          1.6702e-01, -1.4104e-01,  2.2935e-01,  5.4434e-01, -3.9991e-01,\n",
       "          9.1202e-01,  9.0739e-02,  3.8055e-01,  6.4279e-02, -6.3505e-01,\n",
       "          2.2364e-01,  1.2535e+00,  1.7457e-01,  2.9058e-01,  2.9001e-01,\n",
       "          2.7074e-01, -5.3324e-01,  1.5128e-01,  9.4714e-01,  6.5467e-02,\n",
       "         -5.1635e-01, -6.0728e-02, -2.2378e-01,  3.5628e-01, -3.6173e-02,\n",
       "         -2.3567e-01, -3.9440e-02, -3.6019e-01,  4.4116e-01,  4.1642e-01,\n",
       "         -3.2802e-01, -9.6527e-01,  1.8103e-01,  8.3857e-01, -4.1148e-01,\n",
       "         -5.0250e-01, -3.3718e-01, -1.8427e-01,  1.0135e-01, -3.9452e-01,\n",
       "          3.5486e-01,  6.2636e-01,  1.0394e-01, -8.2877e-03, -1.1744e-01,\n",
       "         -5.0739e-01, -3.4047e-01,  6.8704e-02,  3.3825e-02, -4.8983e-01,\n",
       "          3.5001e-01,  2.9329e-01, -1.5962e-01,  1.7126e+00,  4.8570e-01,\n",
       "         -1.6731e-01, -1.1891e+00,  3.9095e-02,  4.0040e-01,  1.7870e-01,\n",
       "         -1.8724e-01, -4.8018e-01,  7.2872e-02, -1.1180e-01, -1.0171e+00,\n",
       "          7.8644e-01,  7.6791e-01,  3.4683e-01,  3.0657e-01,  4.7040e-01,\n",
       "         -3.3419e-01, -8.4489e-01, -3.6324e-01, -4.6800e-01, -1.9390e-01,\n",
       "          3.1363e-01, -3.0196e-01,  6.6714e-01, -2.6783e-01, -3.4787e-01,\n",
       "         -1.9173e-01,  1.1030e-01, -1.1294e-02, -8.5729e-02, -9.5220e-01,\n",
       "         -5.3663e-01,  5.2666e-02,  4.2340e-02,  1.8006e-01, -2.1312e-01,\n",
       "          2.5432e-01,  1.8321e-02, -4.7917e-01, -5.8504e-02, -1.3185e-02,\n",
       "          1.8154e-01, -4.1346e-01, -4.6488e-02, -2.0949e-01, -2.6566e-01,\n",
       "         -1.2465e-01, -2.9623e-02,  1.0665e+00, -3.5139e-02, -3.3732e-01,\n",
       "         -6.9408e-01,  5.0258e-02, -8.0196e-01, -5.4651e-01,  6.3131e-01,\n",
       "          3.7225e-01, -5.4696e-01, -4.2647e-01,  1.2443e-01, -9.4849e-01,\n",
       "          1.8685e-01, -4.0171e-01,  7.0417e-02, -3.0430e-01,  2.9523e-01,\n",
       "          1.5704e-01, -2.1384e-03, -4.5165e-02,  5.3087e-01,  1.5888e-01,\n",
       "         -7.6240e-01,  2.1843e-01, -3.0522e-01,  1.5838e-01,  6.5083e-02,\n",
       "          1.7479e-01,  5.4564e-01,  6.0894e-01,  7.7284e-01,  2.6098e-01,\n",
       "         -8.8295e-01,  2.1163e-01,  1.0816e-02, -4.5218e-01, -4.6132e-01,\n",
       "         -3.2121e-01, -2.3970e-01, -1.0737e+00,  1.9382e-01,  5.7891e-01,\n",
       "         -8.4720e-02,  4.2021e-01,  4.2250e-02,  4.8201e-02,  5.6493e-01,\n",
       "          4.9045e-01,  5.5047e-01,  3.0487e-01, -4.2242e-01, -2.4256e-04,\n",
       "          4.5080e-01,  1.3862e-01, -1.8037e-02,  2.6246e-01, -8.2591e-01,\n",
       "         -3.8836e-02, -1.5055e-01, -1.1764e-01, -3.6450e-01, -1.2038e+00,\n",
       "          1.0167e+00,  8.6208e-02, -3.2350e-01, -1.9597e-01,  3.7691e-01,\n",
       "          9.3823e-01,  1.3646e-01,  5.1882e-01,  3.1312e-01,  3.6373e-01,\n",
       "          3.8933e-01,  1.6703e-01, -5.7794e-01, -1.3774e-02, -1.9940e-01,\n",
       "         -8.0397e-02, -8.8595e-02, -7.3979e-02,  2.7708e-01,  5.7239e-02,\n",
       "         -2.0795e-01,  2.4711e-01, -4.3095e-01,  5.5051e-01,  4.5376e-01,\n",
       "          3.0661e-02,  8.0017e-01,  1.4719e-01, -3.3622e-01,  1.1039e-01,\n",
       "         -5.9332e-01, -3.9195e-01,  1.4756e-01,  7.0164e-01, -2.1758e-01,\n",
       "          5.2751e-01,  2.6164e-01, -4.8284e-02,  2.9027e-01,  3.9139e-01,\n",
       "          6.1368e-02, -8.8559e-01,  1.3885e-01, -9.0510e-01, -3.4729e-01,\n",
       "          3.9655e-01, -1.4456e-01,  5.5187e-01, -5.1599e-01,  5.9949e-01,\n",
       "          8.7997e-01,  3.1912e-01, -4.9277e-01, -3.4751e-01,  2.0208e-01,\n",
       "         -4.2116e-01, -3.2341e-01,  4.1506e-01,  1.5515e-01, -4.8445e-01,\n",
       "          9.3044e-02, -5.0083e-01, -2.7111e-01,  5.8765e-01,  5.3893e-01,\n",
       "         -9.0491e-02, -6.7773e-02,  2.2401e-01, -3.4853e-01, -1.0476e+00,\n",
       "         -4.0965e-01, -3.5831e-01,  3.3834e-01,  8.2414e-02, -2.2765e-01,\n",
       "         -5.4671e-01,  2.1913e-01, -1.6932e-01,  4.2846e-01, -7.2325e-02,\n",
       "         -7.6199e-01, -6.6293e-01, -6.3695e-01, -2.0273e-01,  5.0627e-01,\n",
       "         -2.1841e-01,  3.1868e-01, -9.3608e-03,  5.5890e-01,  3.0798e-01,\n",
       "         -3.1578e-01,  1.1275e-01, -6.6363e-02, -5.4957e-01, -3.7724e-01,\n",
       "         -2.1074e-01, -1.9915e-01, -3.3677e-01, -8.4362e-02, -3.1904e-01,\n",
       "         -6.8855e-02,  2.0514e-02,  3.5813e-01,  5.3882e-01,  2.9330e-01,\n",
       "          3.6868e-01,  9.7368e-01, -4.8594e-01, -5.9382e-01, -1.8088e-01,\n",
       "          2.2370e-01,  1.6355e-01, -6.6161e-01, -1.9140e-01, -2.2429e-01,\n",
       "          8.6867e-01, -9.0617e-01, -4.0055e-02, -8.6385e-02,  1.1757e+00,\n",
       "         -7.6649e-01, -9.0139e-02,  3.8217e-01,  2.9226e-02, -8.8916e-02,\n",
       "         -2.3187e-01,  1.3306e-01, -1.0597e-01, -1.9482e-01,  3.8703e-01,\n",
       "          3.6088e-01,  1.9158e-01,  5.0900e-01,  6.2662e-02,  2.0827e-01,\n",
       "          1.2014e+00, -5.0791e-01, -7.9385e-01, -2.3307e-01, -1.2957e-01,\n",
       "          4.9081e-03, -3.4022e-01, -6.3784e-01, -7.8266e-01, -4.9567e-01,\n",
       "         -2.0152e-01, -5.4818e-01, -6.6497e-01,  2.6151e-01, -3.0411e-01,\n",
       "          4.2437e-01, -6.2440e-01,  1.9580e-01, -3.0580e-01, -2.7154e-01,\n",
       "          4.1373e-01, -1.8420e-01,  4.8244e-02, -2.8064e-01, -7.7329e-03,\n",
       "         -8.3353e-03, -2.2441e-01, -9.0655e-01,  4.4725e-01,  3.8397e-01,\n",
       "         -8.6301e-01, -1.2798e-01, -4.9064e-01, -3.6120e-01, -1.4628e-01,\n",
       "         -3.4208e-01, -1.2872e-01,  1.8503e-01,  2.0390e-01, -3.5741e-01,\n",
       "          5.0068e-01, -1.8333e-01, -5.3916e-02,  5.6739e-01,  2.6921e-01,\n",
       "          3.4741e-02,  4.9272e-01, -2.2096e-01, -8.0080e-02,  1.4941e-02,\n",
       "          3.4117e-01, -1.5129e-02,  5.4385e-01, -6.5253e-02,  9.8013e-01,\n",
       "          1.5716e-01, -1.3689e-01,  4.6826e-01,  2.9372e-01,  3.9265e-01,\n",
       "         -2.3015e-01,  1.8265e-01,  7.1343e-01, -1.0892e+00, -1.0906e-01,\n",
       "          3.8631e-01,  5.9363e-01, -1.4077e+00,  9.7811e-02,  4.3463e-01,\n",
       "         -3.8784e-01,  3.1742e-01,  9.5720e-01,  2.1118e-01, -2.7060e-01,\n",
       "          7.8260e-01,  1.7091e-01,  2.8037e-01,  3.4293e-01, -6.3337e-01,\n",
       "          1.0232e-02, -3.3212e-01,  4.1328e-02,  2.3120e-02,  5.1966e-01,\n",
       "         -7.7458e-01,  1.8136e-01,  2.4481e-01, -3.8035e-01,  6.2343e-02,\n",
       "          6.3250e-01,  1.4098e-01, -8.1452e-01,  3.5300e-01,  1.6367e-01,\n",
       "         -1.3957e-01,  2.6846e-01,  2.0102e-01,  4.2718e-01,  4.8406e-01,\n",
       "         -3.1906e-02,  5.8607e-01, -4.2362e-01,  3.2216e-01,  7.0352e-01,\n",
       "          3.9423e-03,  1.7096e-01,  2.3626e-01,  4.4196e-01,  4.0196e-01,\n",
       "          4.2448e-01,  3.2205e-01,  2.4418e-01, -7.3139e-02, -5.7400e-01,\n",
       "         -4.5258e-01, -6.6287e-01,  1.1054e-01,  7.7566e-01,  2.0539e-01,\n",
       "         -3.3911e-01, -1.1203e+00,  1.4340e-01,  5.7728e-01,  6.5581e-01,\n",
       "         -2.4851e-01, -6.9926e-01, -3.1954e-01,  2.2205e-01, -2.2347e-01,\n",
       "          3.9689e-01, -1.0441e+00, -6.8014e-01, -3.9487e-01, -2.3349e-01,\n",
       "         -4.2392e-01,  3.0080e-01,  4.2204e-01, -2.4760e-01, -2.0841e-01,\n",
       "         -3.1624e-01,  1.9566e-01,  2.8058e-01,  2.8089e-01, -2.2106e-01,\n",
       "         -2.0547e-01, -5.8917e-01,  2.6173e-01, -2.5014e-01,  5.7590e-01,\n",
       "         -2.3873e-01,  2.2090e-01,  2.1252e-01,  7.0359e-01, -6.5154e-01,\n",
       "         -8.1286e-01,  5.8753e-01,  3.6557e-01, -3.2231e-01,  1.1279e+00,\n",
       "         -1.8584e-01,  3.1556e-01,  2.2287e-02, -1.1926e+00, -3.4361e-02,\n",
       "         -3.1805e+00, -3.8988e-02, -7.8197e-01,  1.1043e-01, -1.0612e-01,\n",
       "          3.6626e-01, -5.9467e-02, -1.1748e-01,  6.8008e-02, -4.8582e-01,\n",
       "          6.5287e-01, -3.8891e-03, -8.2219e-02,  1.3996e-01,  3.0244e-01,\n",
       "          7.7209e-01, -2.7803e-01,  8.3476e-02,  7.7678e-01,  5.5110e-01,\n",
       "          1.0430e-01,  4.6664e-01,  5.6498e-01, -3.4669e-01, -5.6437e-01,\n",
       "         -3.2156e-01, -6.7027e-01, -3.7975e-01,  3.9084e-02,  1.2358e-01,\n",
       "          1.1524e-01,  2.1176e-03,  9.1569e-01, -1.7717e-01,  4.8798e-01,\n",
       "          6.1505e-02,  4.5056e-02, -2.7131e-01, -3.9244e-01, -1.8245e-01,\n",
       "         -6.1619e-01, -8.4687e-01,  6.4691e-02, -4.6209e-01,  2.7211e-01,\n",
       "         -5.9559e-02, -7.7808e-01,  5.0239e-02]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "import torch\n",
    "\n",
    "finbert = BertForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"ProsusAI/finbert\", device_map=\"auto\")\n",
    "\n",
    "inputs = tokenizer(\"EXAMPLE SENTENCE\", return_tensors=\"pt\", truncation=True, padding=True)\n",
    "outputs = finbert(**inputs, output_hidden_states=True)\n",
    "# logits = outputs.logits\n",
    "# probabilities = logits.softmax(dim=-1).tolist()[0]\n",
    "\n",
    "outputs.hidden_states[-1].mean(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words for 2020 high_impact:\n",
      "nvidia: 1.0\n",
      "שבת: 0.0\n",
      "פרסום: 0.0\n",
      "פוסט: 0.0\n",
      "מעריב: 0.0\n",
      "לוח: 0.0\n",
      "כניסת: 0.0\n",
      "חדשות: 0.0\n",
      "חגים: 0.0\n",
      "זמני: 0.0\n",
      "Top 10 words for 2020 medium_impact:\n",
      "send: 1.0\n",
      "香港繁中: 0.0\n",
      "台灣繁中: 0.0\n",
      "zz74si: 0.0\n",
      "zoom: 0.0\n",
      "zeus: 0.0\n",
      "zeroday: 0.0\n",
      "zelda: 0.0\n",
      "zealandenglish: 0.0\n",
      "zealand: 0.0\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 389. GiB for an array with shape (1190387, 43840) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[85], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     21\u001b[0m feature_names \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mget_feature_names_out()\n\u001b[0;32m---> 22\u001b[0m tfidf_scores \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mtoarray()[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     24\u001b[0m sorted_items \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mzip\u001b[39m(tfidf_scores, feature_names), reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     25\u001b[0m top_n \u001b[38;5;241m=\u001b[39m sorted_items[:\u001b[38;5;241m10\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/scipy/sparse/_compressed.py:1170\u001b[0m, in \u001b[0;36m_cs_matrix.toarray\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m   1168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m order \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1169\u001b[0m     order \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_swap(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcf\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m-> 1170\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_toarray_args(order, out)\n\u001b[1;32m   1171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mc_contiguous \u001b[38;5;129;01mor\u001b[39;00m out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mf_contiguous):\n\u001b[1;32m   1172\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOutput array must be C or F contiguous\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/scipy/sparse/_base.py:1367\u001b[0m, in \u001b[0;36m_spbase._process_toarray_args\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m   1365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[1;32m   1366\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39morder)\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 389. GiB for an array with shape (1190387, 43840) and data type float64"
     ]
    }
   ],
   "source": [
    "tfidf = {\"2020\": {}, \"2021\": {}, \"2022\": {}, \"2023\": {}, \"2024\": {}, \"2025\": {}}\n",
    "\n",
    "for year in data:\n",
    "    for impact in data[year]:\n",
    "\n",
    "        if data[year][impact] is None:\n",
    "            print(f\"No data for {year} {impact}\")\n",
    "\n",
    "        if len(data[year][impact]) > 0:\n",
    "            text = data[year][impact]\n",
    "            \n",
    "            vectorizer = TfidfVectorizer()\n",
    "\n",
    "            try:\n",
    "                X = vectorizer.fit_transform(text)\n",
    "                tfidf[year][f\"{impact}_tfidf\"] = X\n",
    "            except ValueError as e:\n",
    "                print(f\"Error processing {year} {impact}: {e}\")\n",
    "                continue\n",
    "            \n",
    "            feature_names = vectorizer.get_feature_names_out()\n",
    "            tfidf_scores = X.toarray()[0]\n",
    "\n",
    "            sorted_items = sorted(zip(tfidf_scores, feature_names), reverse=True)\n",
    "            top_n = sorted_items[:10]\n",
    "\n",
    "            print(f\"Top 10 words for {year} {impact}:\")\n",
    "            for score, word in top_n:\n",
    "                print(f\"{word}: {score}\")\n",
    "\n",
    "for year in tfidf:\n",
    "    for impact in tfidf[year]:\n",
    "        data[year][impact] = tfidf[year][impact]\n",
    "\n",
    "del tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "n_components=2 must be between 0 and min(n_samples, n_features)=1 with svd_solver='full'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      4\u001b[0m pca \u001b[38;5;241m=\u001b[39m PCA(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m reduced_matrix \u001b[38;5;241m=\u001b[39m pca\u001b[38;5;241m.\u001b[39mfit_transform(corpus[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2020\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhigh_impact_tfidf\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtoarray())\n\u001b[1;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n\u001b[1;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(reduced_matrix[:, \u001b[38;5;241m0\u001b[39m], reduced_matrix[:, \u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/utils/_set_output.py:319\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 319\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    322\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    323\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    324\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    325\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/decomposition/_pca.py:468\u001b[0m, in \u001b[0;36mPCA.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    447\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model with X and apply the dimensionality reduction on X.\u001b[39;00m\n\u001b[1;32m    448\u001b[0m \n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;124;03m    C-ordered array, use 'np.ascontiguousarray'.\u001b[39;00m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 468\u001b[0m     U, S, _, X, x_is_centered, xp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X)\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m U \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    470\u001b[0m         U \u001b[38;5;241m=\u001b[39m U[:, : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components_]\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/decomposition/_pca.py:542\u001b[0m, in \u001b[0;36mPCA._fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;66;03m# Call different fits for either full or truncated SVD\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_svd_solver \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcovariance_eigh\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_full(X, n_components, xp, is_array_api_compliant)\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_svd_solver \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marpack\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandomized\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_truncated(X, n_components, xp)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/decomposition/_pca.py:556\u001b[0m, in \u001b[0;36mPCA._fit_full\u001b[0;34m(self, X, n_components, xp, is_array_api_compliant)\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    553\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_components=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmle\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is only supported if n_samples >= n_features\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    554\u001b[0m         )\n\u001b[1;32m    555\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m n_components \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(n_samples, n_features):\n\u001b[0;32m--> 556\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    557\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_components=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_components\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be between 0 and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    558\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin(n_samples, n_features)=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mmin\u001b[39m(n_samples,\u001b[38;5;250m \u001b[39mn_features)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    559\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msvd_solver=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_svd_solver\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    560\u001b[0m     )\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_ \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mmean(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    563\u001b[0m \u001b[38;5;66;03m# When X is a scipy sparse matrix, self.mean_ is a numpy matrix, so we need\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;66;03m# to transform it to a 1D array. Note that this is not the case when X\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;66;03m# is a scipy sparse array.\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;66;03m# TODO: remove the following two lines when scikit-learn only depends\u001b[39;00m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;66;03m# on scipy versions that no longer support scipy.sparse matrices.\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: n_components=2 must be between 0 and min(n_samples, n_features)=1 with svd_solver='full'"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "reduced_matrix = pca.fit_transform(corpus[\"2020\"][\"high_impact_tfidf\"].toarray())\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(reduced_matrix[:, 0], reduced_matrix[:, 1])\n",
    "plt.xlabel(\"PCA Component 1\")\n",
    "plt.ylabel(\"PCA Component 2\")\n",
    "plt.title(\"TF-IDF Vectors Visualized with PCA\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 43504)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[\"2020\"][\"news_tfidf\"].toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
